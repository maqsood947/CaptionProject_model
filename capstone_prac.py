# -*- coding: utf-8 -*-
"""capstone prac.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1UnTtjPwbBmTfBlpJwPdP5hqSfqlnDkLj
"""

# Mount Google Drive
from google.colab import drive

# Mount Google Drive
drive.mount('/content/drive')

!7za -y x "/content/drive/MyDrive/Copy of New folder.zip"

mydata= '/content/New folder/color'

from tensorflow.keras.preprocessing.image import ImageDataGenerator

train_datagen = ImageDataGenerator(
    rescale=1./255,         # Normalize pixel values to [0, 1]
    rotation_range=20,      # Randomly rotate images by up to 20 degrees
    width_shift_range=0.2,  # Randomly shift images horizontally by up to 20% of width
    height_shift_range=0.2, # Randomly shift images vertically by up to 20% of height
    shear_range=0.2,        # Shear intensity
    zoom_range=0.2,         # Randomly zoom into images
    horizontal_flip=True,   # Randomly flip images horizontally
    fill_mode='nearest'     # Fill missing pixels using the nearest pixel
)

# Load and augment training data
train_generator = train_datagen.flow_from_directory(
    mydata,
    target_size=(224, 224),  # VGG16 input size
    batch_size=32,
    class_mode='categorical',
    shuffle=True,
    seed=42
)

# import necessary Libraries for Manual Data Splitting
import os
import shutil

# Create train, test, and validation directories
split_dir = '/content/New folder/data_split/'
os.makedirs(split_dir + 'train', exist_ok=True)
os.makedirs(split_dir + 'test', exist_ok=True)
os.makedirs(split_dir + 'val', exist_ok=True)

# Define the percentage split
train_split = 0.7
test_split = 0.2
val_split = 0.1

# Iterate through the original data directory and move images to the split directories
for class_name in os.listdir(mydata):
    class_path = os.path.join(mydata, class_name)

    # Create corresponding directories in the split path
    os.makedirs(os.path.join(split_dir, 'train', class_name), exist_ok=True)
    os.makedirs(os.path.join(split_dir, 'test', class_name), exist_ok=True)
    os.makedirs(os.path.join(split_dir, 'val', class_name), exist_ok=True)

    # List all images in the class directory
    class_images = os.listdir(class_path)
    num_images = len(class_images)

    # Calculate split indices
    train_end = int(train_split * num_images)
    test_end = train_end + int(test_split * num_images)

    # Move images to the appropriate split directory
    for i, image_name in enumerate(class_images):
        image_path = os.path.join(class_path, image_name)
        if i < train_end:
            split_path = os.path.join(split_dir, 'train', class_name)
        elif i < test_end:
            split_path = os.path.join(split_dir, 'test', class_name)
        else:
            split_path = os.path.join(split_dir, 'val', class_name)
        shutil.copy(image_path, os.path.join(split_path, image_name))

# Define new data directories for train, test, and validation

train_data_dir = os.path.join(split_dir, 'train')
test_data_dir = os.path.join(split_dir, 'test')
val_data_dir = os.path.join(split_dir, 'val')

# Data augmentation and preprocessing for validation data
val_datagen = ImageDataGenerator(
    rescale=1./255  # Normalize pixel values to [0, 1] for validation data
)

# Load and augment validation data
val_generator = val_datagen.flow_from_directory(
    val_data_dir,
    target_size=(224, 224),
    batch_size=32,
    class_mode='categorical',
    shuffle=False  # Set shuffle to False for validation data
)

# Data augmentation and preprocessing for test data
test_datagen = ImageDataGenerator(
    rescale=1./255  # Normalize pixel values to [0, 1] for test data
)

# Load and augment test data
test_generator = test_datagen.flow_from_directory(
    test_data_dir,
    target_size=(224, 224),
    batch_size=32,
    class_mode='categorical',
    shuffle=False  # Set shuffle to False for test data
)

# import necessary Libraries to Load VGG16 pre-trained model
from tensorflow.keras.applications import VGG16
from tensorflow.keras import Sequential
from tensorflow.keras.layers import Flatten, Dense, Dropout

# Load the VGG16 model without the top (fully connected) layers
base_model = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))

model = Sequential([
    base_model,
    Flatten(),
    Dense(512, activation='relu'),
    Dropout(0.5),
    Dense(30, activation='softmax')  # 4 classes (Apple Scab, Black Rot, Apple Rust, Apple Healthy)
])

# Freeze the pre-trained layers
for layer in base_model.layers:
    layer.trainable = False

# Compile the model
model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])

# import laibary for TensorBoard Callback
from tensorflow.keras.callbacks import TensorBoard

from tensorflow.keras.callbacks import TensorBoard

# Create a TensorBoard callback
tensorboard_callback = TensorBoard(log_dir="./logs")

# Train the model using the generators and the TensorBoard callback
history = model.fit(
    train_generator,
    validation_data=val_generator,
    epochs=20,
    callbacks=[tensorboard_callback]  # Pass the TensorBoard callback here
)

# Save the model in h5 format
model.save('/content/drive/MyDrive/model.h5')
model.save('my_model.keras')

# import necessary Libraries for Model Evaluation
from sklearn.metrics import classification_report, confusion_matrix
import matplotlib.pyplot as plt
import numpy as np

# Evaluate the model on the test data
test_loss, test_accuracy = model.evaluate(test_generator)
print(f'Test accuracy: {test_accuracy * 100:.2f}%')

predictions = model.predict(test_generator)  # Use test_generator here
predicted_labels = np.argmax(predictions, axis=1)

# True labels
true_labels = test_generator.labels  # Use test_generator.labels here

# Classification report
class_names = list(train_generator.class_indices.keys())
print(classification_report(true_labels, predicted_labels, target_names=class_names))

# Confusion matrix
conf_matrix = confusion_matrix(true_labels, predicted_labels)

# Plot confusion matrix
plt.figure(figsize=(8, 6))
plt.imshow(conf_matrix, interpolation='nearest', cmap=plt.cm.Blues)
plt.title('Confusion Matrix')
plt.colorbar()
tick_marks = np.arange(len(class_names))
plt.xticks(tick_marks, class_names, rotation=45)
plt.yticks(tick_marks, class_names)
plt.xlabel('Predicted')
plt.ylabel('True')
plt.show()

# Commented out IPython magic to ensure Python compatibility.
# Start TensorBoard in Colab
# %load_ext tensorboard
# %tensorboard --logdir ./logs

# definition of Function to test the model with input image
from tensorflow.keras.preprocessing import image

def test_single_image(image_path):
    img = image.load_img(image_path, target_size=(224, 224))
    img = image.img_to_array(img)
    img = np.expand_dims(img, axis=0)
    img = img / 255.0  # Normalize

    prediction = model.predict(img)
    predicted_class = class_names[np.argmax(prediction)]

    plt.imshow(image.load_img(image_path))
    plt.title(f'Predicted Class: {predicted_class}')
    plt.axis('off')
    plt.show()

# Example usage:
test_single_image('/content/frogeye-1.jpg')

test_single_image('/content/septoria-spot-tomato-plant-ea2ab44d-e6f21d609dd04b2f96d96a33e98aab07.jpg')